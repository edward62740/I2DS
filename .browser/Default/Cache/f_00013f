{"html":"\n      <article>\n        <p class=\"banner\"><a href=\"http://docs.silabs.com/gecko-platform/4.0/machine-learning/api/group-ml-audio-feature-generation\" target=\"_blank\" title=\"http://docs.silabs.com/gecko-platform/4.0/machine-learning/api/group-ml-audio-feature-generation\">Open in Browser<\/a><\/p><div class=\"header\">\n  \n  <div class=\"headertitle\">\n  <h1 class=\"title\">Audio Feature Generator<\/h1><\/div>\n<\/div><!--header-->\n<div class=\"contents\">\n<a name=\"details\" id=\"details\"><\/a><h2 class=\"groupheader\">Description<\/h2>\n<p>The audio feature generator extracts mel-filterbank features from an audio signal to use with machine learning audio classification applications using a microphone as an audio source.<\/p>\n<h2><a class=\"anchor\" id=\"autotoc-md1\"><\/a>\nFeature Generation<\/h2>\n<p>The Mel scale replicates the behavior of the human ear, which has a higher resolution for lower frequencies and is less discriminative of the higher frequencies. To create a mel filterbank, a number of filters are applied to the signal, where the pass-band of the lower channel filters is narrow and increases towards higher frequencies.<\/p>\n<p>The audio signal is split into short overlapping segments using a window function (Hamming). The Fast Fourier Transform (FFT) is applied to each segment to retrieve the frequency spectrum and then the power spectrum of the segment. The filterbank is created by applying a series of mel-scaled filters to the output. Finally, the log is applied to the output to increase the sensitivity between the lower channels. <\/p><pre class=\"fragment\">         Audio Signal\n              │\n      ┌───────▼───────┐\n      │   Windowing   │\n      └───────┬───────┘\n              │\n      ┌───────▼───────┐\n      │      FFT      │\n      └───────┬───────┘\n              │\n      ┌───────▼───────┐\n      │  Mel Filters  │\n      └───────┬───────┘\n              │\n      ┌───────▼───────┐\n      │      Log      │\n      └───────┬───────┘\n              │\n              ▼\n   Log-scaled Mel Filterbank\n<\/pre><p>The feature array is generated by stacking filterbanks of sequential segments together to form a spectrogram. The array is sorted such that the first element is the first channel of the oldest filterbank.<\/p>\n<h2><a class=\"anchor\" id=\"autotoc-md2\"><\/a>\nUsage<\/h2>\n<p><a href=\"#ga5e52cfbd7f16eafec4bed1c0bd6349d9\" class=\"el\" title=\"Set up the microphone as an audio source for feature generation and initialize the frontend for featu...\">sl_ml_audio_feature_generation_init()<\/a> initializes the frontend for feature generation based on the configuration in sl_ml_audio_feature_generation_config.h. It also initializes and starts the microphone in streaming mode, which places the audio samples into a ring-buffer.<\/p>\n<p>If used together with the Flatbuffer Converter Tool and a compatible TensorFlow Lite model, the configuration is pulled from the TensorFlow Lite model by default. Set the configuration option <code>SL_ML_AUDIO_FEATURE_GENERATION_MANUAL_CONFIG_ENABLE<\/code> to override this behavior and use manually-configured options from the configuration header.<\/p>\n<p>The features are generated when <a href=\"#ga695dd64a9c813b3eb3c233d40c8f12d0\" class=\"el\" title=\"Update the feature buffer with the missing feature slices since the last call to this function.\">sl_ml_audio_feature_generation_update_features()<\/a> is called. The feature generator then updates the features for as many new segments of audio as possible, starting from the last time the function was called up until the current time. The new features are appended to the feature buffer, replacing the oldest features such that the feature array always contains the most up to date features.<\/p>\n<p>Note that if the audio buffer is not large enough to hold all audio samples required to generate features between calls to <a href=\"#ga695dd64a9c813b3eb3c233d40c8f12d0\" class=\"el\" title=\"Update the feature buffer with the missing feature slices since the last call to this function.\">sl_ml_audio_feature_generation_update_features()<\/a>, audio data will simply be overwritten. The generator will not return an error. The audio buffer must therefore be configured to be large enough to store all new sampled data between updating features.<\/p>\n<p>To retrieve the generated features, either <a href=\"#ga0c5428b1d2d140615eb668da566a8ca9\" class=\"el\" title=\"Retrieve the features as type uint16 and copy them to the provided buffer.\">sl_ml_audio_feature_generation_get_features_raw()<\/a>, sl_ml_audio_feature_generation_get_features_quantized(), or <a href=\"#ga7538fff5979d8f2511498b3ad1c19583\" class=\"el\" title=\"Fill a TensorFlow tensor with feature data of type int8.\">sl_ml_audio_feature_generation_fill_tensor()<\/a> must be called.<\/p>\n<h3><a class=\"anchor\" id=\"autotoc-md3\"><\/a>\nExample<\/h3>\n<p>When used with TensorFlow Lite Micro, the audio feature generator can be used to fill a tensor directly by using <a href=\"#ga7538fff5979d8f2511498b3ad1c19583\" class=\"el\" title=\"Fill a TensorFlow tensor with feature data of type int8.\">sl_ml_audio_feature_generation_fill_tensor()<\/a>. However, the model has to be trained using the same feature generator configurations as used for inference, configured in sl_ml_audio_feature_generation_config.h.<\/p>\n<div class=\"fragment\"><div class=\"line\"><span class=\"preprocessor\">#include \"sl_tflite_micro_init.h\"<\/span><\/div>\n<div class=\"line\"><span class=\"preprocessor\">#include \"sl_ml_audio_feature_generation.h\"<\/span><\/div>\n<div class=\"line\"> <\/div>\n<div class=\"line\"><span class=\"keywordtype\">void<\/span> main(<span class=\"keywordtype\">void<\/span>)<\/div>\n<div class=\"line\">{<\/div>\n<div class=\"line\">  <a href=\"#ga5e52cfbd7f16eafec4bed1c0bd6349d9\" class=\"code\">sl_ml_audio_feature_generation_init<\/a>();<\/div>\n<div class=\"line\"> <\/div>\n<div class=\"line\">  <span class=\"keywordflow\">while<\/span>(1){<\/div>\n<div class=\"line\">    <a href=\"#ga695dd64a9c813b3eb3c233d40c8f12d0\" class=\"code\">sl_ml_audio_feature_generation_update_features<\/a>();<\/div>\n<div class=\"line\"> <\/div>\n<div class=\"line\">    <span class=\"keywordflow\">if<\/span>(do_inference){<\/div>\n<div class=\"line\">      <a href=\"#ga7538fff5979d8f2511498b3ad1c19583\" class=\"code\">sl_ml_audio_feature_generation_fill_tensor<\/a>(<a href=\"http://docs.silabs.com/gecko-platform/4.0/machine-learning/api/group-tflite-micro-init#gac62cdedf565108ae89250e58066b1cde\" class=\"code\" target=\"_blank\">sl_tflite_micro_get_input_tensor<\/a>());<\/div>\n<div class=\"line\">      <a href=\"http://docs.silabs.com/gecko-platform/4.0/machine-learning/api/group-tflite-micro-init#gaa5b6ec2a71637b12b8c789dc96351fc6\" class=\"code\" target=\"_blank\">sl_tflite_micro_get_interpreter<\/a>()-&gt;Invoke();<\/div>\n<div class=\"line\">    }<\/div>\n<div class=\"line\"> <\/div>\n<div class=\"line\">    ...<\/div>\n<div class=\"line\"> <\/div>\n<div class=\"line\">  }<\/div>\n<div class=\"line\">}<\/div>\n<\/div><!-- fragment --><p>Note that updating features and retrieving them can be performed independently. Updating features should be done often enough to avoid overwriting the audio buffer while retrieving them only needs to be done prior to inference. <\/p>\n<table class=\"memberdecls\">\n<tbody><tr class=\"heading\"><td colspan=\"2\"><h2 class=\"groupheader\"><a name=\"func-members\"><\/a>\nFunctions<\/h2><\/td><\/tr>\n<tr class=\"memitem\"><td class=\"memItemLeft\" align=\"right\" valign=\"top\">sl_status_t&nbsp;<\/td><td class=\"memItemRight\" valign=\"bottom\"><a href=\"#ga5e52cfbd7f16eafec4bed1c0bd6349d9\" class=\"el\">sl_ml_audio_feature_generation_init<\/a> ()<\/td><\/tr>\n<tr class=\"memdesc\"><td class=\"mdescLeft\">&nbsp;<\/td><td class=\"mdescRight\">Set up the microphone as an audio source for feature generation and initialize the frontend for feature generation.  <br><\/td><\/tr>\n<tr class=\"separator\"><td class=\"memSeparator\" colspan=\"2\">&nbsp;<\/td><\/tr>\n<tr class=\"memitem\"><td class=\"memItemLeft\" align=\"right\" valign=\"top\">sl_status_t&nbsp;<\/td><td class=\"memItemRight\" valign=\"bottom\"><a href=\"#gabab6eb482b7962d089e69c8d7994bcb7\" class=\"el\">sl_ml_audio_feature_generation_frontend_init<\/a> ()<\/td><\/tr>\n<tr class=\"memdesc\"><td class=\"mdescLeft\">&nbsp;<\/td><td class=\"mdescRight\">Initialize microfrontend according to the configuration in sl_ml_audio_feature_generation_config.h.  <br><\/td><\/tr>\n<tr class=\"separator\"><td class=\"memSeparator\" colspan=\"2\">&nbsp;<\/td><\/tr>\n<tr class=\"memitem\"><td class=\"memItemLeft\" align=\"right\" valign=\"top\">sl_status_t&nbsp;<\/td><td class=\"memItemRight\" valign=\"bottom\"><a href=\"#ga695dd64a9c813b3eb3c233d40c8f12d0\" class=\"el\">sl_ml_audio_feature_generation_update_features<\/a> ()<\/td><\/tr>\n<tr class=\"memdesc\"><td class=\"mdescLeft\">&nbsp;<\/td><td class=\"mdescRight\">Update the feature buffer with the missing feature slices since the last call to this function.  <br><\/td><\/tr>\n<tr class=\"separator\"><td class=\"memSeparator\" colspan=\"2\">&nbsp;<\/td><\/tr>\n<tr class=\"memitem\"><td class=\"memItemLeft\" align=\"right\" valign=\"top\">sl_status_t&nbsp;<\/td><td class=\"memItemRight\" valign=\"bottom\"><a href=\"#ga0c5428b1d2d140615eb668da566a8ca9\" class=\"el\">sl_ml_audio_feature_generation_get_features_raw<\/a> (uint16_t *buffer, size_t num_elements)<\/td><\/tr>\n<tr class=\"memdesc\"><td class=\"mdescLeft\">&nbsp;<\/td><td class=\"mdescRight\">Retrieve the features as type uint16 and copy them to the provided buffer.  <br><\/td><\/tr>\n<tr class=\"separator\"><td class=\"memSeparator\" colspan=\"2\">&nbsp;<\/td><\/tr>\n<tr class=\"memitem\"><td class=\"memItemLeft\" align=\"right\" valign=\"top\">sl_status_t&nbsp;<\/td><td class=\"memItemRight\" valign=\"bottom\"><a href=\"#ga7538fff5979d8f2511498b3ad1c19583\" class=\"el\">sl_ml_audio_feature_generation_fill_tensor<\/a> (TfLiteTensor *input_tensor)<\/td><\/tr>\n<tr class=\"memdesc\"><td class=\"mdescLeft\">&nbsp;<\/td><td class=\"mdescRight\">Fill a TensorFlow tensor with feature data of type int8.  <br><\/td><\/tr>\n<tr class=\"separator\"><td class=\"memSeparator\" colspan=\"2\">&nbsp;<\/td><\/tr>\n<tr class=\"memitem\"><td class=\"memItemLeft\" align=\"right\" valign=\"top\">int&nbsp;<\/td><td class=\"memItemRight\" valign=\"bottom\"><a href=\"#ga9a9dec0bb63186cff33e9632c89c6a4b\" class=\"el\">sl_ml_audio_feature_generation_get_new_feature_slice_count<\/a> ()<\/td><\/tr>\n<tr class=\"memdesc\"><td class=\"mdescLeft\">&nbsp;<\/td><td class=\"mdescRight\">Return the number of new or unfetched feature slices that have been updated since the last call to sl_ml_audio_feature_generation_get_features_raw or sl_ml_audio_feature_generation_fill_tensor.  <br><\/td><\/tr>\n<tr class=\"separator\"><td class=\"memSeparator\" colspan=\"2\">&nbsp;<\/td><\/tr>\n<tr class=\"memitem\"><td class=\"memItemLeft\" align=\"right\" valign=\"top\">int&nbsp;<\/td><td class=\"memItemRight\" valign=\"bottom\"><a href=\"#ga1429f1112b35b4bbdf4d0231b1905dfd\" class=\"el\">sl_ml_audio_feature_generation_get_feature_buffer_size<\/a> ()<\/td><\/tr>\n<tr class=\"memdesc\"><td class=\"mdescLeft\">&nbsp;<\/td><td class=\"mdescRight\">Return the feature buffer size.  <br><\/td><\/tr>\n<tr class=\"separator\"><td class=\"memSeparator\" colspan=\"2\">&nbsp;<\/td><\/tr>\n<tr class=\"memitem\"><td class=\"memItemLeft\" align=\"right\" valign=\"top\">void&nbsp;<\/td><td class=\"memItemRight\" valign=\"bottom\"><a href=\"#ga52fcdbfa257f5319b1b493d21d4ac78d\" class=\"el\">sl_ml_audio_feature_generation_reset<\/a> ()<\/td><\/tr>\n<tr class=\"memdesc\"><td class=\"mdescLeft\">&nbsp;<\/td><td class=\"mdescRight\">Reset the state of the audio feature generator.  <br><\/td><\/tr>\n<tr class=\"separator\"><td class=\"memSeparator\" colspan=\"2\">&nbsp;<\/td><\/tr>\n<\/tbody><\/table>\n<h2 class=\"groupheader\">Function Documentation<\/h2>\n<a id=\"ga5e52cfbd7f16eafec4bed1c0bd6349d9\"><\/a>\n<h2 class=\"memtitle\"><span class=\"permalink\"><a href=\"#ga5e52cfbd7f16eafec4bed1c0bd6349d9\">◆&nbsp;<\/a><\/span>sl_ml_audio_feature_generation_init()<\/h2>\n\n<div class=\"memitem\">\n<div class=\"memproto\">\n      <table class=\"memname\">\n        <tbody><tr>\n          <td class=\"memname\">sl_status_t sl_ml_audio_feature_generation_init <\/td>\n          <td>(<\/td>\n          <td class=\"paramname\"><code><\/code><\/td><td>)<\/td>\n          <td><\/td>\n        <\/tr>\n      <\/tbody><\/table>\n<\/div><div class=\"memdoc\">\n\n<p>Set up the microphone as an audio source for feature generation and initialize the frontend for feature generation. <\/p>\n<dl class=\"section return\"><dt>Returns<\/dt><dd>SL_STATUS_OK for success SL_STATUS_FAIL <\/dd><\/dl>\n\n<\/div>\n<\/div>\n<a id=\"gabab6eb482b7962d089e69c8d7994bcb7\"><\/a>\n<h2 class=\"memtitle\"><span class=\"permalink\"><a href=\"#gabab6eb482b7962d089e69c8d7994bcb7\">◆&nbsp;<\/a><\/span>sl_ml_audio_feature_generation_frontend_init()<\/h2>\n\n<div class=\"memitem\">\n<div class=\"memproto\">\n      <table class=\"memname\">\n        <tbody><tr>\n          <td class=\"memname\">sl_status_t sl_ml_audio_feature_generation_frontend_init <\/td>\n          <td>(<\/td>\n          <td class=\"paramname\"><code><\/code><\/td><td>)<\/td>\n          <td><\/td>\n        <\/tr>\n      <\/tbody><\/table>\n<\/div><div class=\"memdoc\">\n\n<p>Initialize microfrontend according to the configuration in sl_ml_audio_feature_generation_config.h. <\/p>\n<dl class=\"section return\"><dt>Returns<\/dt><dd>SL_STATUS_OK for success SL_STATUS_FAIL <\/dd><\/dl>\n\n<\/div>\n<\/div>\n<a id=\"ga695dd64a9c813b3eb3c233d40c8f12d0\"><\/a>\n<h2 class=\"memtitle\"><span class=\"permalink\"><a href=\"#ga695dd64a9c813b3eb3c233d40c8f12d0\">◆&nbsp;<\/a><\/span>sl_ml_audio_feature_generation_update_features()<\/h2>\n\n<div class=\"memitem\">\n<div class=\"memproto\">\n      <table class=\"memname\">\n        <tbody><tr>\n          <td class=\"memname\">sl_status_t sl_ml_audio_feature_generation_update_features <\/td>\n          <td>(<\/td>\n          <td class=\"paramname\"><code><\/code><\/td><td>)<\/td>\n          <td><\/td>\n        <\/tr>\n      <\/tbody><\/table>\n<\/div><div class=\"memdoc\">\n\n<p>Update the feature buffer with the missing feature slices since the last call to this function. <\/p>\n<p>To retrieve the features, call sl_ml_audio_feature_generation_get_features_raw or sl_ml_audio_feature_generation_fill_tensor.<\/p>\n<dl class=\"section note\"><dt>Note<\/dt><dd>This function needs to be called often enough to ensure that the audio buffer isn't overwritten.<\/dd><\/dl>\n<dl class=\"section return\"><dt>Returns<\/dt><dd>SL_STATUS_OK for success SL_STATUS_EMPTY No new slices were calculated <\/dd><\/dl>\n\n<\/div>\n<\/div>\n<a id=\"ga0c5428b1d2d140615eb668da566a8ca9\"><\/a>\n<h2 class=\"memtitle\"><span class=\"permalink\"><a href=\"#ga0c5428b1d2d140615eb668da566a8ca9\">◆&nbsp;<\/a><\/span>sl_ml_audio_feature_generation_get_features_raw()<\/h2>\n\n<div class=\"memitem\">\n<div class=\"memproto\">\n      <table class=\"memname\">\n        <tbody><tr>\n          <td class=\"memname\">sl_status_t sl_ml_audio_feature_generation_get_features_raw <\/td>\n          <td>(<\/td>\n          <td class=\"paramtype\">uint16_t *&nbsp;<\/td>\n          <td class=\"paramname\"><code>buffer, <\/code><\/td>\n        <\/tr>\n        <tr>\n          <td class=\"paramkey\"><\/td>\n          <td><\/td>\n          <td class=\"paramtype\">size_t&nbsp;<\/td>\n          <td class=\"paramname\"><code>num_elements&nbsp;<\/code><\/td>\n        <\/tr>\n        <tr>\n          <td><\/td>\n          <td>)<\/td>\n          <td><\/td><td><\/td>\n        <\/tr>\n      <\/tbody><\/table>\n<\/div><div class=\"memdoc\">\n\n<p>Retrieve the features as type uint16 and copy them to the provided buffer. <\/p>\n<dl class=\"params\"><dt>Parameters<\/dt><dd>\n  <table class=\"params\">\n    <tbody><tr><td class=\"paramdir\">[out]<\/td><td class=\"paramname\"><code>buffer<\/code><\/td><td>Pointer to the buffer to store the feature data<\/td><\/tr>\n    <tr><td class=\"paramdir\">[in]<\/td><td class=\"paramname\"><code>num_elements<\/code><\/td><td>The number of elements corresponding to the size of the buffer; If this is not large enough to store the entire feature buffer the function will return with an error.<\/td><\/tr>\n  <\/tbody><\/table>\n  <\/dd>\n<\/dl>\n<dl class=\"section note\"><dt>Note<\/dt><dd>This function overwrites the entire buffer.<\/dd><\/dl>\n<dl class=\"section return\"><dt>Returns<\/dt><dd>SL_STATUS_OK for success SL_STATUS_INVALID_PARAMETER num_elements too small <\/dd><\/dl>\n\n<\/div>\n<\/div>\n<a id=\"ga7538fff5979d8f2511498b3ad1c19583\"><\/a>\n<h2 class=\"memtitle\"><span class=\"permalink\"><a href=\"#ga7538fff5979d8f2511498b3ad1c19583\">◆&nbsp;<\/a><\/span>sl_ml_audio_feature_generation_fill_tensor()<\/h2>\n\n<div class=\"memitem\">\n<div class=\"memproto\">\n      <table class=\"memname\">\n        <tbody><tr>\n          <td class=\"memname\">sl_status_t sl_ml_audio_feature_generation_fill_tensor <\/td>\n          <td>(<\/td>\n          <td class=\"paramtype\">TfLiteTensor *&nbsp;<\/td>\n          <td class=\"paramname\"><code>input_tensor<\/code><\/td><td>)<\/td>\n          <td><\/td>\n        <\/tr>\n      <\/tbody><\/table>\n<\/div><div class=\"memdoc\">\n\n<p>Fill a TensorFlow tensor with feature data of type int8. <\/p>\n<p>The int8 values are derived by quantizing the microfrontend output, expected to be in the range 0 to 670, to signed integer numbers in -128 to 127 range.<\/p>\n<dl class=\"params\"><dt>Parameters<\/dt><dd>\n  <table class=\"params\">\n    <tbody><tr><td class=\"paramdir\">[in]<\/td><td class=\"paramname\"><code>input_tensor<\/code><\/td><td>The input tensor to fill with features.<\/td><\/tr>\n  <\/tbody><\/table>\n  <\/dd>\n<\/dl>\n<dl class=\"section note\"><dt>Note<\/dt><dd>This function overwrites the entire input tensor.<\/dd>\n<dd>\nSupports tensors of type kTfLiteInt8.<\/dd><\/dl>\n<dl class=\"section return\"><dt>Returns<\/dt><dd>SL_STATUS_OK for success SL_STATUS_INVALID_PARAMETER Tensor type or size does not correspond with configuration <\/dd><\/dl>\n\n<\/div>\n<\/div>\n<a id=\"ga9a9dec0bb63186cff33e9632c89c6a4b\"><\/a>\n<h2 class=\"memtitle\"><span class=\"permalink\"><a href=\"#ga9a9dec0bb63186cff33e9632c89c6a4b\">◆&nbsp;<\/a><\/span>sl_ml_audio_feature_generation_get_new_feature_slice_count()<\/h2>\n\n<div class=\"memitem\">\n<div class=\"memproto\">\n      <table class=\"memname\">\n        <tbody><tr>\n          <td class=\"memname\">int sl_ml_audio_feature_generation_get_new_feature_slice_count <\/td>\n          <td>(<\/td>\n          <td class=\"paramname\"><code><\/code><\/td><td>)<\/td>\n          <td><\/td>\n        <\/tr>\n      <\/tbody><\/table>\n<\/div><div class=\"memdoc\">\n\n<p>Return the number of new or unfetched feature slices that have been updated since the last call to sl_ml_audio_feature_generation_get_features_raw or sl_ml_audio_feature_generation_fill_tensor. <\/p>\n<dl class=\"section return\"><dt>Returns<\/dt><dd>The number of unfetched feature slices <\/dd><\/dl>\n\n<\/div>\n<\/div>\n<a id=\"ga1429f1112b35b4bbdf4d0231b1905dfd\"><\/a>\n<h2 class=\"memtitle\"><span class=\"permalink\"><a href=\"#ga1429f1112b35b4bbdf4d0231b1905dfd\">◆&nbsp;<\/a><\/span>sl_ml_audio_feature_generation_get_feature_buffer_size()<\/h2>\n\n<div class=\"memitem\">\n<div class=\"memproto\">\n      <table class=\"memname\">\n        <tbody><tr>\n          <td class=\"memname\">int sl_ml_audio_feature_generation_get_feature_buffer_size <\/td>\n          <td>(<\/td>\n          <td class=\"paramname\"><code><\/code><\/td><td>)<\/td>\n          <td><\/td>\n        <\/tr>\n      <\/tbody><\/table>\n<\/div><div class=\"memdoc\">\n\n<p>Return the feature buffer size. <\/p>\n<dl class=\"section return\"><dt>Returns<\/dt><dd>Size of the feature buffer <\/dd><\/dl>\n\n<\/div>\n<\/div>\n<a id=\"ga52fcdbfa257f5319b1b493d21d4ac78d\"><\/a>\n<h2 class=\"memtitle\"><span class=\"permalink\"><a href=\"#ga52fcdbfa257f5319b1b493d21d4ac78d\">◆&nbsp;<\/a><\/span>sl_ml_audio_feature_generation_reset()<\/h2>\n\n<div class=\"memitem\">\n<div class=\"memproto\">\n      <table class=\"memname\">\n        <tbody><tr>\n          <td class=\"memname\">void sl_ml_audio_feature_generation_reset <\/td>\n          <td>(<\/td>\n          <td class=\"paramname\"><code><\/code><\/td><td>)<\/td>\n          <td><\/td>\n        <\/tr>\n      <\/tbody><\/table>\n<\/div><div class=\"memdoc\">\n\n<p>Reset the state of the audio feature generator. <\/p>\n\n<\/div>\n<\/div>\n<\/div>\n      <div ub-in-page=\"6062051aebaf71079a7b414b\"><\/div>\n      <\/article>\n    ","url":"http://docs.silabs.com/gecko-platform/4.0/machine-learning/api/group-ml-audio-feature-generation","status":"success"}
